\documentclass[es,practica]{uah}

\usepackage{hyperref}

\tema{1}
\titulo{Teoría de la Información. Codificación de fuente}{Lesson title}
%
\begin{document}

\titulacion{Optativa GIEC y GIT}
\departamento{Teoría de la Señal y Comunicaciones}
\asignatura{Comunicaciones Digitales}{}
\curso{2021/2022}

\maketitle

\begin{abstract}
Comenzaremos esta práctica repasando el concepto de entropía, para a continuación ver dos ejemplos de codificadores de fuente, como son los códigos Huffman y los códigos LZW (Lempel-Ziv-Welch). Se verán asimismo dos ejemplos adiconales de codificación fuente aplicada a los casos particulares de ficheros de audio y de imagen. 
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%
\section{Introducción}
%%%%%%%%%%%%%%%%%%%%%%

La práctica se dividirá a su vez en cuatro subprácticas que se incluyen en los ficheros \texttt{Practica1a.ipynb}, \texttt{Practica1b.ipynb}, \texttt{Practica1c.ipynb} y \texttt{Practica1d.ipynb}. Todos ellos son notebooks de Jupyter que pueden ser ejecutados en cualquier ordenador con una distribución de Python y un editor adecuado. 

Además, se incluye un archivo Python, \texttt{CodFuente.py}, con una serie de funciones relacionadas con la codificación fuente:
\begin{itemize}
	\item {\bf entropia}
	\item {\bf gen_huffman_dic}
	\item {\bf huffman\_cod}
	\item {\bf huffman\_dec}
	\item {\bf gen_lzw_dic}
	\item {\bf lzw\_cod}
	\item {\bf lzw\_dec}
\end{itemize}


Dentro de este archivo veréis que faltan por desarrollar algunas funciones que se han dejado en blanco:
\begin{itemize}
	\item {\bf entropia}: Esta función debe tomar a su entrada un mensaje en formato \emph{string} ó \emph{List}, y devolver a su salida el valor de la entropía para dicha fuente. Podéis aprovecharos de las salidas de la función \emph{gen\_huffman\_dic} para coger de ahí las probabilidades de cada uno de los símbolos.
	\item {\bf huffman\_cod}: Toma a su entrada dos parámetros: un mensaje a codificar, en formato \emph{string} y el diccionario de códigos con pares carácter/símbolo. Debe devolver a su salida el mensaje codificado en formato binario como una cadena \emph{string}.
\end{itemize}

Se puede comprobar el funcionamiento de todas estas funciones utilizando la cadena de datos ``una prueba''. Se debería obtener una entropía de $2.92$ y los siguientes resultados:
\begin{itemize}
	\item Probabilidades: \begin{verbatim}{'u': 0.2, 'n': 0.1, 'a': 0.2, ' ': 0.1, 'p': 0.1, 'r': 0.1, 'e': 0.1, 'b': 0.1}\end{verbatim}
	\item Códigos: \begin{verbatim}{'u': '10', 'a': '111', 'e': '000', 'n': '001', 'p': '010', 'r': '011', ' ': '1100', 'b': '1101'}\end{verbatim}
	\item Mensaje codificado: \begin{verbatim}100011111100010011100001101111\end{verbatim}
	

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Codificación Huffman}
%%%%%%%%%%%%%%%%%%%%%%%%%%
Una vez hayáis completado estas funciones ya podéis abrir el fichero \texttt{Practica1a.ipynb} y ejecutarlo. Comprobad que la salida del sistema coincida con la entrada, y añadid el código necesario para mostrar por pantalla los valores que obtenéis de los tamaños de los archivos en cada fase.

%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Codificación LZW}
%%%%%%%%%%%%%%%%%%%%%%%%%%

Repetid lo mismo para el fichero \texttt{Practica1b.ipynb}. En este caso ya están implementadas todas las funciones para la codificación y tan sólo debéis añadir el código para mostrar por pantalla los tamaños del mensaje en cada etapa del sistema.

%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Codificación de audio}
%%%%%%%%%%%%%%%%%%%%%%%%%%
Para el caso de archivos de audio (y de imagen, como veremos más adelante), es posible utilizar algunas estrategias ligeramente distintas a las que hemos visto. En estos casos ese habla de codificación con pérdidas (lo que hacen los sistemas mp3, aac, mp4 y similares), ya que vamos a reducir el tamaño del archivo, al igual que hemos hecho antes, pero en este caso vamos a asumir que el archivo resultante no sea igual que el original, aunque sí lo suficientemente parecido como para que las diferencias no sean perceptibles. Este tipo de codificadores se denominan a veces ''codificadores de destino`` ya que basan gran parte de su funcionamiento en las características del receptor (en el caso del audio, el oído humano).

La idea es muy simple. Previamente a la codificación Huffman, lo que se hace es aplicar un cuantificador al archivo original, con la idea de reducir el número de bits por muestra de los 16 que suelen ser normales en los ficheros de audio a un valor mucho menor. Como sabemos, el hecho de realizar una cuantificación va a implicar necesariamente que se introduzca un determinado ruido de cuantificación (cuantos menos bits utilicemos por muestra, mayor será el ruido de cuantificación). Un codificador de audio lo que va a hacer es intentar controlar este ruido de cuantificación de modo que quede enmascarado por el sonido original, de forma que no sea audible. Si se hace correctamente, el archivo codificado y el original serían prácticamente indistinguibles desde un punto de vista perceptual. 

Nosotros vamos a hacer algo mucho más sencillo, pero que permite observar el funcionamiento de un sistema de este tipo. En el archivo \texttt{Practica1c.ipynb} se realiza la codificación de un archivo de audio de dos formas distintas:

\begin{itemize}
	\item {\bf En el dominio del tiempo}: Esto no es lo habitual (de hecho nunca se hace así), pero como primera aproximación lo que hacemos es simplemente recuantificar el archivo original, aplicarle un codificador Huffman y deshacer todo el proceso en recepción. Podéis observar el resultado final en el archivo \emph{salida_tiempo.wav}.
	\item {\bf En el dominio de la frecuencia}: En este caso lo que se hace es dividir el fichero de audio en tramas de N muestras, y para cada una de ellas se calcula una transformada al dominio de la frecuencia (usamos una transformada del coseno, DCT, en lugar de una transformada de Fourier porque devuelve valores reales, lo que facilita el trabajo). Una vez en el dominio de la frecuencia, se recuantifica cada una de las tramas, se le aplica un codificador Huffman, y el receptor deshace todo el proceso. La razón de trabajar de esta manera es que el proceso de enmascaramiento del oído humano también funciona en el domino de la frecuencia, por lo que al trabajar en este dominio podemos ajustar mucho mejor el funcionamiento del codificador a las características del sonido. En este caso podéis ver la salida del codificador en el archivo \emph{salida_frecuencia.wav}.
\end{itemize}


En realidad el proceso es algo más complejo. Si queréis profundizar algo más podéis echarle un ojo a este tutorial para haceros una idea: \url{https://ieeexplore.ieee.org/document/618009}. Podéis acceder a él desde la intranet de la UAH o utilizando la VPN. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Archivo de imagen}
%%%%%%%%%%%%%%%%%%%%%%%%%%%

Este apartado tiene como idea complementar lo ya hecho anteriormente con un ejemplo de aplicación real como es la codificación de imágenes. En concreto vamos a pensar en una versión muy simplificada de un codificador JPEG que es lo que podéis encontrar en el archivo \texttt{Practica1d.ipynb}.

JPEG se enmarca dentro de lo que se conocen como codificadores con pérdidas. Esto quiere decir que la imagen original nunca se va a poder volver a reconstruir a partir de la imagen en formato JPEG, ya que hay partes de la información que se van a eliminar. Igual que antes, esta información se elimina de forma que su impacto visual sobre la imagen sea el menor posible, de forma que, si todo va bien, la imagen JPEG y la imagen original sean prácticamente idénticas. 

Para conseguir todo esto, el algoritmo JPEG hace lo siguiente con la imagen (vamos a pensar por simplicidad que tenemos una imagen en escala de grises):

\begin{enumerate}
\item Antes de nada, convertimos los valores de cada pixel de la imagen de formato \emph{entero sin signo} a \emph{entero con signo}. Para un caso como el que vamos a considerar, en el que la imagen viene codificada con 8 bits por muestra, esto implica simplemente restarle $2^7 = 128$ a cada muestra, de forma que los valores pasan de $[0, 255]$ a $[-128, 127]$.
\item Ahora procesamos la imagen en bloques de 8x8 píxeles.
\item Se calcula la Transformada del Coseno (DCT) para cada bloque. Como comentábamos antes, la DCT es una variante de la transformada de Fourier en la que las funciones base en lugar de ser exponenciales complejas son cosenos. Esto tiene algunas limitaciones que no vienen al caso, pero también tiene una gran ventaja, y es que los valores de la DCT son reales, por lo que reducimos a la mitad la información a codificar con respecto a una DFT normal.
\item Se cuantifica el bloque transformado utilizando una matriz de cuantificación. El estándar propone una, aunque luego cada fabricante puede utilizar una propia. Si llamamos $Q$ a la matriz de cuantificación y $X$ al bloque obtenido tras la DCT, el proceso es simplemente:
\begin{equation}
	X_q = Round \left ( \frac{X}{Q} \right )
\end{equation}
\item Se aplica un proceso de codificación Huffman a la señal cuantificada
\end{enumerate}

Una vez en el decodificador, se siguen los pasos inversos para cada bloque:

\begin{enumerate}
\item Hacemos la cuantificación inversa:
\begin{equation}
	X_R = X_q \cdot Q
\end{equation}
\item Calculamos la transformada inversa del coseno (IDCT).
\end{enumerate}


En realidad lo que se hace es que se codifica de forma separada el primer pixel de cada bloque de 8x8 (que tiene un valor muy superior al resto de píxeles del bloque)\footnote{Si accedéis desde la UAH, o con VPN, podéis echarle un ojo a este tutorial para haceros una idea: \url{https://ieeexplore.ieee.org/document/125072}}. El valor de estos píxeles iniciales de cada bloque se codifica de forma diferencial con el del anterior bloque, ahorrando así algún bit extra, y el resto de los píxeles sí que se codifican utilizando un código Huffman, ordenando los valores siguiendo un patron en diagonal.



\section{¿Qué hay que entregar?}

\begin{itemize}
	\item Todos los archivos con el código completado tal y como se indica antes. 
	\item Un documento de texto en el que se responda a lo siguiente:
	\begin{itemize}
		\item ¿Qué diferencias aprecias entre la codificación Huffman y la LZW para el archivo de texto?
		\item Para el caso del archivo de audio, ¿qué diferencia existe entre trabajar en el dominio del tiempo o en el dominio transformado? ¿Qué sucede si aumentas o disminuyes el valor del escalón de cuantificación (está en la parte de Configuración del archivo \texttt{Practica1c.ipynb})?
		\item Lo mismo para el caso de la imagen. ¿Cómo afecta el valor del factor de calidad a los resultados?
	\end{itemize}
\end{itemize}

\end{document}



	
